# Deep-Learning-from-scratch
## Overview
This repository contains manual implementations of core deep learning architectures using only Python and NumPy, without relying on high-level machine learning libraries such as TensorFlow or PyTorch.
The goal of this project is to build a deep foundational understanding of how neural networks function internally by coding every component from scratch. This repository will help you gain an in depth understanding of the working of every function we commonly use in making any deep learning model.

---

## Models Implemented

* **Simple Perceptron** — single-layer basic unit.
* **Multi-Layer Perceptron (MLP)** — deep feedforward networks with activation functions.
* **Convolutional Neural Networks (CNNs)** — manual implementation of convolutions, pooling, and feature extraction layers.
* **Recurrent Neural Networks (RNNs)** — modeling sequential data and temporal patterns.
* **Long Short-Term Memory (LSTM)** — capturing long-term dependencies in sequences through gated memory cells.

[PS. The code files are currently missing in the repository. They wil be uploaded very soon!]
